{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "# 00\n",
    "# 文字列 \"stressed\" の文字を逆順にして得る\n",
    "\n",
    "string = \"stressed\"\n",
    "reverted_str = string[::-1]\n",
    "print(reverted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タクシー\n"
     ]
    }
   ],
   "source": [
    "# 01\n",
    "# 「パタトクカシーー」という文字列の1, 3, 5, 7文字目を取り出して連結した文字列を得る\n",
    "\n",
    "string = \"パタトクカシーー\"\n",
    "joined_str = [string[i] for i in range(len(string)) if (i % 2 == 1)]\n",
    "output = \"\".join(joined_str)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "# 02\n",
    "# 「パトカー」と「タクシー」の文字列を先頭から連結して「パタトクカシーー」の文字列を作る\n",
    "\n",
    "s1 = \"パトカー\"\n",
    "s2 = \"タクシー\"\n",
    "joined_s = [a + b for a, b in zip(s1, s2)]\n",
    "output = \"\".join(joined_s)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# 03 \n",
    "# 次の文を単語に分解し、各単語の文字数を戦闘から出現順に並べて得る\n",
    "import re\n",
    "\n",
    "SENTENCE = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "nonsymbol_SENTENCE = re.sub(r\"\\.|,\", \"\", SENTENCE)\n",
    "words = nonsymbol_SENTENCE.split(\" \")\n",
    "num_words = [len(words[i]) for i in range(len(words))]\n",
    "\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 0, 'He': 1, 'Li': 2, 'Be': 3, 'B': 4, 'C': 5, 'N': 6, 'O': 7, 'F': 8, 'Ne': 9, 'Na': 10, 'Mi': 11, 'Al': 12, 'Si': 13, 'P': 14, 'S': 15, 'Cl': 16, 'Ar': 17, 'K': 18, 'Ca': 19}\n"
     ]
    }
   ],
   "source": [
    "# 04\n",
    "# 次の文を単語に分解して、1, 5, 6, 7, 8, 9, 15, 16, 19番目の文字は1文字、それ以外の単語は戦闘の2文字を取り出し、その文字列から単語のⅠへの連想配列を作成する。\n",
    "\n",
    "SENTENCE = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "ONE_CHAR = (0, 4, 5, 6, 7, 8, 14, 15, 18)\n",
    "\n",
    "words = SENTENCE.split(\" \")\n",
    "heads = []\n",
    "for i in range(len(words)):\n",
    "    if(i in ONE_CHAR):\n",
    "        heads.append(words[i][:1])\n",
    "    else:\n",
    "        heads.append(words[i][:2])\n",
    "\n",
    "num_words = [i for i in range(len(words))]\n",
    "heads_dict = dict(zip(heads, num_words))\n",
    "\n",
    "print(heads_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "# 05 \n",
    "# 与えられたシーケンスからn-gramを作る関数を作成する\n",
    "\n",
    "SENTENCE = \"I am an NLPer\"\n",
    "\n",
    "def make_ngram(sentence, n):\n",
    "    ngram = []\n",
    "    i = 0\n",
    "    while(True):\n",
    "        group = sentence[i:i+n]\n",
    "        ngram.append(group)\n",
    "        i += 1\n",
    "        if(i + n > len(sentence)):\n",
    "            break\n",
    "    return ngram\n",
    "\n",
    "word_bigram = make_ngram(SENTENCE.split(\" \"), 2)\n",
    "char_bigram = make_ngram(SENTENCE, 2)\n",
    "\n",
    "print(word_bigram)\n",
    "print(char_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ap', 'ag', 'di', 'ad', 'pa', 'se', 'ra', 'ph', 'ar', 'gr', 'is'}\n",
      "{'ap', 'pa', 'ra', 'ar'}\n",
      "{'is', 'di', 'ad', 'se'}\n"
     ]
    }
   ],
   "source": [
    "# 06\n",
    "# 次の２つのシーケンスからbi-gramの集合を得て、 それらの和集合、積集合、差集合を求める\n",
    "\n",
    "SENTENCE1 = \"paraparaparadise\"\n",
    "SENTENCE2 = \"paragraph\"\n",
    "\n",
    "X = make_ngram(SENTENCE1, 2)\n",
    "Y = make_ngram(SENTENCE2, 2)\n",
    "X = set(X)\n",
    "Y = set(Y)\n",
    "\n",
    "union = X | Y\n",
    "intersection = X & Y\n",
    "set_dif = X - Y\n",
    "\n",
    "print(union)\n",
    "print(intersection)\n",
    "print(set_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "# 07\n",
    "# x, y, z を引数として受け取り、「x時のyはz」という文字列を返す関数を実装する\n",
    "\n",
    "def temp(x, y, z):\n",
    "    return str(x) + \"時の\" + str(y) + \"は\" + str(z)\n",
    "\n",
    "result = temp(12, \"気温\", 22.4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy.\n",
      "I zn szkkb.\n"
     ]
    }
   ],
   "source": [
    "# 08\n",
    "# 次のように文字列を返還する関数chipherを実装する。英小文字なら、(219 - 文字コード)の文字に置換し、それ以外ならそのまま出力する\n",
    "\n",
    "import re\n",
    "\n",
    "def cipher(sentence):\n",
    "    converted_s = []\n",
    "    for i in range(len(sentence)):\n",
    "        c = sentence[i]\n",
    "        if(re.match(\"[a-z]\", c)):\n",
    "            converted_s.append(chr(219 - ord(c)))\n",
    "        else:\n",
    "            converted_s.append(c)\n",
    "    converted_s = \"\".join(converted_s)\n",
    "    return converted_s\n",
    "\n",
    "s = \"I am happy.\"\n",
    "result = cipher(s)\n",
    "print(s)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\n",
      "I cn’udolt bveliee that I colud allctauy uernsnatdd what I was rdaneig : the paohenmnel pweor of the hmuan mind .\n"
     ]
    }
   ],
   "source": [
    "# 09\n",
    "# Typoglycemia\n",
    "# 単語列に対して、各単語の先頭と末尾の文字は残し、それ以外の文字をランダムに並び替えるプログラムを作成する。ただし、４文字以下の単語には適用しない。\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def typoglycemia(sentence):\n",
    "    words = sentence.split(\" \")\n",
    "    \n",
    "    result = []\n",
    "    for word in words:\n",
    "        if(len(word) > 4):\n",
    "            conv_w = list(word)[1:-1]\n",
    "            random.shuffle(conv_w)\n",
    "            conv_w.insert(0, word[0])\n",
    "            conv_w.append(word[-1])\n",
    "            conv_w = \"\".join(conv_w)\n",
    "\n",
    "            result.append(conv_w)\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return \" \".join(result)\n",
    "\n",
    "\n",
    "SENTENCE = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "\n",
    "result = typoglycemia(SENTENCE)\n",
    "print(SENTENCE)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2790b9310a930223f4d316af7336933ab376078410078d4517d2e40c9bbcc22e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
